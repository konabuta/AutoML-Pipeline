{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Machine Learning\n",
    "_**ディープラーンニングを利用したテキスト分類**_\n",
    "\n",
    "## Contents\n",
    "1. [事前準備](#1.-事前準備)\n",
    "1. [自動機械学習 Automated Machine Learning](2.-自動機械学習-Automated-Machine-Learning)\n",
    "1. [結果の確認](#3.-結果の確認)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 事前準備\n",
    "\n",
    "本デモンストレーションでは、AutoML の深層学習の機能を用いてテキストデータの分類モデルを構築します。  \n",
    "AutoML には Deep Neural Network が含まれており、テキストデータから **Embedding** を作成することができます。GPU サーバを利用することで **BERT** が利用されます。\n",
    "\n",
    "深層学習の機能を利用するためには Azure Machine Learning の Enterprise Edition が必要になります。詳細は[こちら](https://docs.microsoft.com/en-us/azure/machine-learning/concept-editions#automated-training-capabilities-automl)をご確認ください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Python SDK のインポート"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Azure Machine Learning の Python SDK などをインポートします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (portalocker 2.0.0 (/anaconda/envs/azureml_py36/lib/python3.6/site-packages), Requirement.parse('portalocker~=1.0'), {'msal-extensions'}).\n"
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core.run import Run\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core.model import Model \n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.automl.core.featurization import FeaturizationConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Azure ML Python SDK のバージョンが 1.8.0 以上になっていることを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "You are currently using version 1.11.0 of the Azure ML SDK\n"
    }
   ],
   "source": [
    "print(\"You are currently using version\", azureml.core.VERSION, \"of the Azure ML SDK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Azure ML Workspace との接続"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                  \nWorkspace Name   azureml_text                     \nResource Group   azureml_text                     \nLocation         japaneast                        \nExperiment Name  livedoor-news-classification-BERT",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Workspace Name</th>\n      <td>azureml_text</td>\n    </tr>\n    <tr>\n      <th>Resource Group</th>\n      <td>azureml_text</td>\n    </tr>\n    <tr>\n      <th>Location</th>\n      <td>japaneast</td>\n    </tr>\n    <tr>\n      <th>Experiment Name</th>\n      <td>livedoor-news-classification-BERT</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "\n",
    "# 実験名の指定\n",
    "experiment_name = 'livedoor-news-classification-BERT'\n",
    "\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "\n",
    "output = {}\n",
    "#output['Subscription ID'] = ws.subscription_id\n",
    "output['Workspace Name'] = ws.name\n",
    "output['Resource Group'] = ws.resource_group\n",
    "output['Location'] = ws.location\n",
    "output['Experiment Name'] = experiment.name\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "outputDf = pd.DataFrame(data = output, index = [''])\n",
    "outputDf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 計算環境の準備\n",
    "\n",
    "BERT を利用するための GPU の `Compute Cluster` を準備します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Succeeded\nAmlCompute wait for completion finished\n\nMinimum number of nodes requested have been provisioned\n"
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Compute Cluster の名称\n",
    "amlcompute_cluster_name = \"gpucluster\"\n",
    "\n",
    "# クラスターの存在確認\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=amlcompute_cluster_name)\n",
    "    \n",
    "except ComputeTargetException:\n",
    "    print('指定された名称のクラスターが見つからないので新規に作成します.')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_NC6_V3\",\n",
    "                                                           max_nodes = 4)\n",
    "    compute_target = ComputeTarget.create(ws, amlcompute_cluster_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 学習データの準備\n",
    "今回は [livedoor New](https://www.rondhuit.com/download/ldcc-20140209.tar.gz) を学習データとして利用します。ニュースのカテゴリー分類のモデルを構築します。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column_name = 'label'  # カテゴリーの列 \n",
    "feature_column_name = 'text'  # ニュース記事の列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "            label  \\\n0  dokujo-tsushin   \n1  dokujo-tsushin   \n2  dokujo-tsushin   \n3  dokujo-tsushin   \n4  dokujo-tsushin   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 text  \n0  　「お願いがあるんだけど……友人代表のスピーチ、やってくれないかな？」　さてそんなとき、独女はどう対応したらいいか？　最近だとインターネット等で検索すれば友人代表スピーチ用の例文サイトがたくさん出てくるので、それらを参考にすれば、無難なものは誰でも作成できる。しかし由利さん（33歳）はネットを参考にして作成したものの「これで本当にいいのか不安でした。一人暮らしなので聞かせて感想をいってくれる人もいないし、かといって他の友人にわざわざ聞かせるのもどうかと思うし……」ということで活用したのが、なんとインターネットの悩み相談サイトに。そこに作成したスピーチ文を掲載し「これで大丈夫か添削してください」とメッセージを送ったというのである。　「一晩で3人位の人が添削してくれましたよ。ちなみに自分以外にもそういう人はたくさんいて、その相談サイトには同じように添削をお願いする投稿がいっぱいありました」（由利さん）。ためしに教えてもらったそのサイトをみてみると、確かに「結婚式のスピーチの添削お願いします」という投稿が1000件を超えるくらいあった。めでたい結婚式の影でこんなネットコミュニティがあったとは知らなかった。　しかし「事前にお願いされるスピーチなら準備ができるしまだいいですよ。一番嫌なのは何といってもサプライズスピーチ！」と語るのは昨年だけで10万以上お祝いにかかったというお祝い貧乏独女の薫さん（35歳）　「私は基本的に人前で話すのが苦手なんですよ。だからいきなり指名されるとしどろもどろになって何もいえなくなる。そうすると自己嫌悪に陥って終わった後でもまったく楽しめなくなりますね」　　サプライズスピーチのメリットとしては、準備していない状態なので、フランクな本音をしゃべってもらえるという楽しさがあるようだ。しかしそれも上手に対応できる人ならいいが、苦手な人の場合だと「フランク」ではなく「しどろもどろ」になる危険性大。ちなみにプロの司会者の場合、本当のサプライズではなく式の最中に「のちほどサプライズスピーチとしてご指名させていただきます」という一言があることも多いようだが、薫さん曰く「そんな何分前に言われても無理！」らしい。要は「サプライズを楽しめる」というタイプの人選が大切ということか。　一方「ありきたりじゃつまらないし、ネットで例文を検索している際に『こんな方法もあるのか！』って思って取り入れました」という幸恵さん（30歳）が行ったスピーチは「手紙形式のスピーチ」というもの。　「○○ちゃんへ　みたいな感じで新婦の友人にお手紙を書いて読み上げるやり方です。これなら多少フランクな書き方でも大丈夫だし、何より暗記しないで堂々と読み上げることができますよね。読んだものはそのまま友人にあげれば一応記念にもなります」（幸恵さん）なるほど、確かにこれなら読みあげればいいだけなので、人前で話すのが苦手な人でも失敗しないかもしれない。　主役はあくまで新郎新婦ながらも、いざとなると緊張し、内容もあれこれ考えて、こっそりリハーサル……そんな人知れず頑張るスピーチ担当独女たちにも幸あれ（高山惠）                                                           \n1  　「5年前に別れた彼からメールが届いてビックリしました」とは尚美さん（36歳）　「彼の浮気が原因で別れたのですが、現在は独り身らしいことが書いてありました。ただ、私には婚約間近の恋人がいるのでスルー。もし自分に相手がいなかったら、復活愛はあったかも。出会いの機会が少ない独女にとって、いい時代と言えるのでは？」　彼と交際していた当時、尚美さんは実家に住んでいた。もしもメールも携帯電話もない時代だったら、恐らく彼からの連絡はあり得なかっただろう。　一方、美加子さん（38歳）は「一般電話だけの時代のほうが、縁を切りにくかったですよ」という。　「今はメモリ頼りになっている分、電話番号やメールアドレスを消去してしまえばそれまでってところがありますからね。ずるずる引きずろうと思えば引きずれるし、切ろうと思えば切れる。ひと昔前は彼の電話番号を暗記していたものです。受話器を上げたり戻したり……気持ちを断つのが難しかったなぁ」　知恵さん（34歳）も同意見だ。　「情報は自分が情報網を使えば入ってくるが　自分次第でシャットアウトできるもの。だけど私は、“別れた彼と絶縁すべき”とは思っていません。心が癒されるまでの期間は連絡を断ちきり、それ以降はメールを送るなどして、友達関係に戻ることが多いですね」　オール・オア・ナッシングだった以前に比べ、今は縁を切る、友人に戻る、メル友関係を続けるなど、別れた後の関係性を選択できるようになった。未練が残っているうちは辛いが、ツールを上手く使えばメリットを得られることもあるだろう。ただし、落とし穴もある。最後に、律子さん（35歳）のトホホな話を紹介。　「10年前につきあっていた元彼とは、節目節目にメールをしています。“マイミク”で日記にコメントを書き込んだりもするし、年賀状もやりとりする仲。元彼はすでに結婚して子どもが二人いるんですね。最近はすっかり中年太りしてきてマイホームパパって感じ。いい人ではあるけど、すっかり気持ちが冷めた今となっては、なぜ自分があれほど彼に執着していたのか疑問に思えてくる。過去の恋愛の想い出をきれい残したいのなら、知らないほうがいいこともあるかもしれません」　恋の思い出は脳内で美化されるもの。ネットなどで友情関係を続けるのはよいが、同時に淡く切ない恋の思い出は生活感、現実感にまみれてしまうことがあるので、繋ぎすぎには注意したいところ。ま、お互い様ですけどね。（来布十和）                                                                                                                                                                                                                                                                                                                                                       \n2  　今年に入ってから、“すっぴん”をブログで披露した芸能人は、小倉優子、安倍なつみ、モーニング娘。の田中れいな、優木まおみ、仲里依紗など、年齢も活躍しているジャンルも様々。私生活をリアルタイムに発信できるブログだからこそ、皆それぞれにリラックスした表情で自分のすっぴんを公開している。ファンにとっては、好きな芸能人の素顔が垣間見れる嬉しいサービスなのだろう。　では、なぜ芸能人のすっぴん顔披露に、彼女は疑問を抱いたのだろうか。「私のひがみだと言う事は重々承知なんですけど、“随分自分に自信があるんだな”って、素直にその美しさを認める事が出来なくて…」と話す香さん。「コメントに“すっぴんでもかわいい！”とか、“メイクしなくても全然OK！”とか賞賛ばかりが並ぶのを見越して、すっぴん写真を公開してるんだなって思うと何か複雑ですね」と付け加えた。　本来ファンサービスである為のすっぴん披露を、「話題を呼ぶ為や、コメントで褒められたいから」行っているのでは？　と、独女はつい“ナナメ”に見てしまう様だ。また、メーカーで営業をしている裕美さん（仮名／32歳）は「男性の“すっぴん幻想”には参りますね。そりゃ素顔がキレイならば私だってすっぴんで出社しますよ。でも、毎日少しでもキレイになりたいと一生懸命メイクしている努力も認めて欲しいな」と独女なりの乙女心を明かしてくれた。　「10代や20代前半の若い女の子がすっぴんを載せているのは、“ああ、やっぱり可愛いな”と心から思えるんですけど、私と同年代の人が披露していると自分のすっぴんと比べてゲンナリします」と、美しい芸能人すっぴんを見た後に独女達は人知れず傷ついているのである。　さて、芸能人のすっぴん披露、実際に男性の評判はどうなのだろうか。アパレル企業に勤める雄介さん（仮名／34歳）は「個人的に女性のメイクした顔に魅力を感じないから、すっぴんを見るとすごく可愛いと思う」と賛成派。一方、IT企業で働く徹さん（仮名／28歳）は「人によるけど、何でわざわざブログに載せるんだろうとは思います。本来、女性のすっぴんは大切な相手にだけ見せて欲しいんですよ。“あ、俺だけに見せてくれた”って感じで（笑）」と男性陣の意見もそれぞれの様だ。　今後、ブーム化する予感もあるブログでのすっぴん披露。肯定派と反対派に分かれている様だが、男性が女性の“すっぴん”に特別な想いを持っている事は確か。独女達も、いつかすっぴんを披露するその時の為に、素顔を磨く必要があるのかもしれない。                                                                                                                                                                                                                                                                                                                         \n3  　これは、４月に開催されたワコール人間科学研究所の記者発表「からだのエイジング（加齢による体型変化）について一定の法則を発見」での内容の一部。延べ4万人分の経年変化の数値を集計・分析したデータとともに、写真や映像で説明させるので説得力は抜群だ。　現実を直視させられた後に、体型変化の少ない人達の身体的特徴や日常の行動・意識を紹介。その主な内容は、日頃から体を動かし、姿勢をチェック、下着は必ず試着してフィット感を確かめるというもの。そして、パネルディスカッションでは、歩幅の広い歩き方を１年間続ける実験に参加した人が、背筋が伸び、脂肪が落ちたという結果などが紹介されていた。　興味は尽きず、知人たちに内容を伝えるとさまざまな意見や経験が聞けた。　「ずっと計測されているから、体型変化の少ない人はスポーツをしてたのでは？」という疑問もあったが、この回答は、「運動を一生懸命しているというより日常生活を気をつけている印象が強い。そして、ダイエットはあまりしたことがない」とのこと。　「叔母もそんなことを言っていた」と言うのはＹ子。60歳代の叔母さんが友人たちと温泉旅行に行ったとき、「バストの変化が少ないとほめられた」と喜んでいたので、バストのケア方法を尋ねたそうだ。「叔母はブラジャーを常に着用し、購入時は必ず計測して試着している。一方、友人達は『苦しい』からと家ではブラジャーをしないこともあるらしい」。それを聞いて以来、Ｙ子は下着を買うときには試着はもちろん、計ってもらうようにしている。　「私も歩いてやせた」と話すのは、腰痛に悩まされていたＫ子。医師に筋力の低下を指摘されて、駅までの自転車を止めて、片道30分の道のりを毎日往復歩くことに。筋力をつけるために始めたことで体全体が引き締まり、結果として減量にも成功した。　「でも、スポーツすればしまるよね」と言うＡ子は、不摂生がたたって気になり始めたウエスト回りをスポーツクラブに通って改善。ジーンズがワンサイズ小さくなったと喜んでいる。　パネルディスカッションでは、「加齢は一方通行だが、現状維持は可能」「アンチエイジングは医学界でも注目だが、身体的な美しさの維持と健康維持の関係性は表裏一体のはず」とも言われていた。それならば、体型変化という加齢への抵抗はあきらめないほうが得策だ。杉本彩が言っていたっけ、「若いころに戻りたいとか、若く見られたい、とは思わない。今の自分がどう美しくあるかを追求したい」って。（オフィスエムツー／オオノマキ）詳細はコチラ                                                                                                                                                                                                                                                                                                                      \n4  　先日は在日外国人男性がタイで養子縁組をしたと称する554人分の子ども手当を申請しようとして市から却下されたニュースが報じられたが、悪い人間がちょっと考えれば簡単に不正ができるような不備だらけの子ども手当って、一体どうなっているの？ と支給されない側の独女からも疑問の声が聞こえる。　現在独身の由梨さんは、「私立の幼稚園にベンツで送り迎えをしているような家にどうして子ども手当が必要なの？」と一律支給にはどうしても納得できないと訴える。　　「子ども手当はフランスの真似をしたと聞いていますけど、フランスでは子ども手当は“家族手当”といい所得制限はありません。でも家族手当が貰えるのは第2子からで20歳まで支給され、３人目からは割増の家族手当が貰えるそうです。子ども手当が少子化対策を目的にしたものなら、フランスのように2人目から手当を出すべきではないですか？」　一律支給だけをフランスの真似をするのはおかしいという。　それに少子化対策と言われながら、子ども手当を当てにして出産しようという声は聞かない。　「政権交代をすればなくなるかもしれない手当を期待して、今から結婚してもすぐに妊娠するとは限らないし、無事出産の暁には子ども手当は廃止されているかもしれないですよね」　その可能性もなきにしもあらずだ。　子ども手当の使い道について子どものいる主婦に聞くと、将来の教育費のために貯蓄に回すという人が多かった。それについても、　「子どもが欲しくてもできなかった家庭がその費用を負担するのはとてもお気の毒な気がします。それに本当に子どものために使われるのならいいのですが、親がギャンブルに使ったり、親の遊興費に使われるために私たちの税金を使ってほしくないですね」と由梨さん。　バツイチの綾さんは、「子どものいない夫婦も、独身も、働いて税金を納めることで次世代を担う子どもたちを育てることに貢献する。それが子ども手当だと思っていましたが、子どものいる家庭にいくはずのお金がどんどん減らされ、それがどこへ行くのかわからないし、申請書の偽装で、私たちの税金が外国人の子どものところに行くのは納得ができません」と制度の不備に怒っている。　　「所得制限限度額のある児童手当を増額するべきなのに、全世帯平等に子ども手当てをばらまくのは選挙のための人気とりしか思えません。これで政権が変われば子ども手当はどうなるのか？」　もしこのまま子ども手当をばら撒かれれば、将来子ども手当をもらった子どもたちが増税という形でつけを払わされるのではと綾さんは心配もしていたが、財政難を地方に泣きつく地方負担に地方自治体から反発の声が上がっている。　一体どうなってしまうのか？ 今後の子ども手当をしっかり見守りたい。　ところで今回、子どものいない独身の人たちに意見を聞いたのだが、「子ども手当」は自分たちには関係ないのでよく分からないという独女が多かった。　介護保険についても、実際自分が親の介護をする立場になって初めて内容かを知ったという人が多いのだが、どんな制度も国会を通過して施行されれば私たちの納めた税金が使われるのだ。知ることも文句を言うことだって私たちの権利だと思う。無関心でいるよりはよほどいいのではないだろうか。（オフィスエムツー／佐枝せつこ）  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dokujo-tsushin</td>\n      <td>「お願いがあるんだけど……友人代表のスピーチ、やってくれないかな？」　さてそんなとき、独女はどう対応したらいいか？　最近だとインターネット等で検索すれば友人代表スピーチ用の例文サイトがたくさん出てくるので、それらを参考にすれば、無難なものは誰でも作成できる。しかし由利さん（33歳）はネットを参考にして作成したものの「これで本当にいいのか不安でした。一人暮らしなので聞かせて感想をいってくれる人もいないし、かといって他の友人にわざわざ聞かせるのもどうかと思うし……」ということで活用したのが、なんとインターネットの悩み相談サイトに。そこに作成したスピーチ文を掲載し「これで大丈夫か添削してください」とメッセージを送ったというのである。　「一晩で3人位の人が添削してくれましたよ。ちなみに自分以外にもそういう人はたくさんいて、その相談サイトには同じように添削をお願いする投稿がいっぱいありました」（由利さん）。ためしに教えてもらったそのサイトをみてみると、確かに「結婚式のスピーチの添削お願いします」という投稿が1000件を超えるくらいあった。めでたい結婚式の影でこんなネットコミュニティがあったとは知らなかった。　しかし「事前にお願いされるスピーチなら準備ができるしまだいいですよ。一番嫌なのは何といってもサプライズスピーチ！」と語るのは昨年だけで10万以上お祝いにかかったというお祝い貧乏独女の薫さん（35歳）　「私は基本的に人前で話すのが苦手なんですよ。だからいきなり指名されるとしどろもどろになって何もいえなくなる。そうすると自己嫌悪に陥って終わった後でもまったく楽しめなくなりますね」　　サプライズスピーチのメリットとしては、準備していない状態なので、フランクな本音をしゃべってもらえるという楽しさがあるようだ。しかしそれも上手に対応できる人ならいいが、苦手な人の場合だと「フランク」ではなく「しどろもどろ」になる危険性大。ちなみにプロの司会者の場合、本当のサプライズではなく式の最中に「のちほどサプライズスピーチとしてご指名させていただきます」という一言があることも多いようだが、薫さん曰く「そんな何分前に言われても無理！」らしい。要は「サプライズを楽しめる」というタイプの人選が大切ということか。　一方「ありきたりじゃつまらないし、ネットで例文を検索している際に『こんな方法もあるのか！』って思って取り入れました」という幸恵さん（30歳）が行ったスピーチは「手紙形式のスピーチ」というもの。　「○○ちゃんへ　みたいな感じで新婦の友人にお手紙を書いて読み上げるやり方です。これなら多少フランクな書き方でも大丈夫だし、何より暗記しないで堂々と読み上げることができますよね。読んだものはそのまま友人にあげれば一応記念にもなります」（幸恵さん）なるほど、確かにこれなら読みあげればいいだけなので、人前で話すのが苦手な人でも失敗しないかもしれない。　主役はあくまで新郎新婦ながらも、いざとなると緊張し、内容もあれこれ考えて、こっそりリハーサル……そんな人知れず頑張るスピーチ担当独女たちにも幸あれ（高山惠）</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dokujo-tsushin</td>\n      <td>「5年前に別れた彼からメールが届いてビックリしました」とは尚美さん（36歳）　「彼の浮気が原因で別れたのですが、現在は独り身らしいことが書いてありました。ただ、私には婚約間近の恋人がいるのでスルー。もし自分に相手がいなかったら、復活愛はあったかも。出会いの機会が少ない独女にとって、いい時代と言えるのでは？」　彼と交際していた当時、尚美さんは実家に住んでいた。もしもメールも携帯電話もない時代だったら、恐らく彼からの連絡はあり得なかっただろう。　一方、美加子さん（38歳）は「一般電話だけの時代のほうが、縁を切りにくかったですよ」という。　「今はメモリ頼りになっている分、電話番号やメールアドレスを消去してしまえばそれまでってところがありますからね。ずるずる引きずろうと思えば引きずれるし、切ろうと思えば切れる。ひと昔前は彼の電話番号を暗記していたものです。受話器を上げたり戻したり……気持ちを断つのが難しかったなぁ」　知恵さん（34歳）も同意見だ。　「情報は自分が情報網を使えば入ってくるが　自分次第でシャットアウトできるもの。だけど私は、“別れた彼と絶縁すべき”とは思っていません。心が癒されるまでの期間は連絡を断ちきり、それ以降はメールを送るなどして、友達関係に戻ることが多いですね」　オール・オア・ナッシングだった以前に比べ、今は縁を切る、友人に戻る、メル友関係を続けるなど、別れた後の関係性を選択できるようになった。未練が残っているうちは辛いが、ツールを上手く使えばメリットを得られることもあるだろう。ただし、落とし穴もある。最後に、律子さん（35歳）のトホホな話を紹介。　「10年前につきあっていた元彼とは、節目節目にメールをしています。“マイミク”で日記にコメントを書き込んだりもするし、年賀状もやりとりする仲。元彼はすでに結婚して子どもが二人いるんですね。最近はすっかり中年太りしてきてマイホームパパって感じ。いい人ではあるけど、すっかり気持ちが冷めた今となっては、なぜ自分があれほど彼に執着していたのか疑問に思えてくる。過去の恋愛の想い出をきれい残したいのなら、知らないほうがいいこともあるかもしれません」　恋の思い出は脳内で美化されるもの。ネットなどで友情関係を続けるのはよいが、同時に淡く切ない恋の思い出は生活感、現実感にまみれてしまうことがあるので、繋ぎすぎには注意したいところ。ま、お互い様ですけどね。（来布十和）</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>dokujo-tsushin</td>\n      <td>今年に入ってから、“すっぴん”をブログで披露した芸能人は、小倉優子、安倍なつみ、モーニング娘。の田中れいな、優木まおみ、仲里依紗など、年齢も活躍しているジャンルも様々。私生活をリアルタイムに発信できるブログだからこそ、皆それぞれにリラックスした表情で自分のすっぴんを公開している。ファンにとっては、好きな芸能人の素顔が垣間見れる嬉しいサービスなのだろう。　では、なぜ芸能人のすっぴん顔披露に、彼女は疑問を抱いたのだろうか。「私のひがみだと言う事は重々承知なんですけど、“随分自分に自信があるんだな”って、素直にその美しさを認める事が出来なくて…」と話す香さん。「コメントに“すっぴんでもかわいい！”とか、“メイクしなくても全然OK！”とか賞賛ばかりが並ぶのを見越して、すっぴん写真を公開してるんだなって思うと何か複雑ですね」と付け加えた。　本来ファンサービスである為のすっぴん披露を、「話題を呼ぶ為や、コメントで褒められたいから」行っているのでは？　と、独女はつい“ナナメ”に見てしまう様だ。また、メーカーで営業をしている裕美さん（仮名／32歳）は「男性の“すっぴん幻想”には参りますね。そりゃ素顔がキレイならば私だってすっぴんで出社しますよ。でも、毎日少しでもキレイになりたいと一生懸命メイクしている努力も認めて欲しいな」と独女なりの乙女心を明かしてくれた。　「10代や20代前半の若い女の子がすっぴんを載せているのは、“ああ、やっぱり可愛いな”と心から思えるんですけど、私と同年代の人が披露していると自分のすっぴんと比べてゲンナリします」と、美しい芸能人すっぴんを見た後に独女達は人知れず傷ついているのである。　さて、芸能人のすっぴん披露、実際に男性の評判はどうなのだろうか。アパレル企業に勤める雄介さん（仮名／34歳）は「個人的に女性のメイクした顔に魅力を感じないから、すっぴんを見るとすごく可愛いと思う」と賛成派。一方、IT企業で働く徹さん（仮名／28歳）は「人によるけど、何でわざわざブログに載せるんだろうとは思います。本来、女性のすっぴんは大切な相手にだけ見せて欲しいんですよ。“あ、俺だけに見せてくれた”って感じで（笑）」と男性陣の意見もそれぞれの様だ。　今後、ブーム化する予感もあるブログでのすっぴん披露。肯定派と反対派に分かれている様だが、男性が女性の“すっぴん”に特別な想いを持っている事は確か。独女達も、いつかすっぴんを披露するその時の為に、素顔を磨く必要があるのかもしれない。</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>dokujo-tsushin</td>\n      <td>これは、４月に開催されたワコール人間科学研究所の記者発表「からだのエイジング（加齢による体型変化）について一定の法則を発見」での内容の一部。延べ4万人分の経年変化の数値を集計・分析したデータとともに、写真や映像で説明させるので説得力は抜群だ。　現実を直視させられた後に、体型変化の少ない人達の身体的特徴や日常の行動・意識を紹介。その主な内容は、日頃から体を動かし、姿勢をチェック、下着は必ず試着してフィット感を確かめるというもの。そして、パネルディスカッションでは、歩幅の広い歩き方を１年間続ける実験に参加した人が、背筋が伸び、脂肪が落ちたという結果などが紹介されていた。　興味は尽きず、知人たちに内容を伝えるとさまざまな意見や経験が聞けた。　「ずっと計測されているから、体型変化の少ない人はスポーツをしてたのでは？」という疑問もあったが、この回答は、「運動を一生懸命しているというより日常生活を気をつけている印象が強い。そして、ダイエットはあまりしたことがない」とのこと。　「叔母もそんなことを言っていた」と言うのはＹ子。60歳代の叔母さんが友人たちと温泉旅行に行ったとき、「バストの変化が少ないとほめられた」と喜んでいたので、バストのケア方法を尋ねたそうだ。「叔母はブラジャーを常に着用し、購入時は必ず計測して試着している。一方、友人達は『苦しい』からと家ではブラジャーをしないこともあるらしい」。それを聞いて以来、Ｙ子は下着を買うときには試着はもちろん、計ってもらうようにしている。　「私も歩いてやせた」と話すのは、腰痛に悩まされていたＫ子。医師に筋力の低下を指摘されて、駅までの自転車を止めて、片道30分の道のりを毎日往復歩くことに。筋力をつけるために始めたことで体全体が引き締まり、結果として減量にも成功した。　「でも、スポーツすればしまるよね」と言うＡ子は、不摂生がたたって気になり始めたウエスト回りをスポーツクラブに通って改善。ジーンズがワンサイズ小さくなったと喜んでいる。　パネルディスカッションでは、「加齢は一方通行だが、現状維持は可能」「アンチエイジングは医学界でも注目だが、身体的な美しさの維持と健康維持の関係性は表裏一体のはず」とも言われていた。それならば、体型変化という加齢への抵抗はあきらめないほうが得策だ。杉本彩が言っていたっけ、「若いころに戻りたいとか、若く見られたい、とは思わない。今の自分がどう美しくあるかを追求したい」って。（オフィスエムツー／オオノマキ）詳細はコチラ</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>dokujo-tsushin</td>\n      <td>先日は在日外国人男性がタイで養子縁組をしたと称する554人分の子ども手当を申請しようとして市から却下されたニュースが報じられたが、悪い人間がちょっと考えれば簡単に不正ができるような不備だらけの子ども手当って、一体どうなっているの？ と支給されない側の独女からも疑問の声が聞こえる。　現在独身の由梨さんは、「私立の幼稚園にベンツで送り迎えをしているような家にどうして子ども手当が必要なの？」と一律支給にはどうしても納得できないと訴える。　　「子ども手当はフランスの真似をしたと聞いていますけど、フランスでは子ども手当は“家族手当”といい所得制限はありません。でも家族手当が貰えるのは第2子からで20歳まで支給され、３人目からは割増の家族手当が貰えるそうです。子ども手当が少子化対策を目的にしたものなら、フランスのように2人目から手当を出すべきではないですか？」　一律支給だけをフランスの真似をするのはおかしいという。　それに少子化対策と言われながら、子ども手当を当てにして出産しようという声は聞かない。　「政権交代をすればなくなるかもしれない手当を期待して、今から結婚してもすぐに妊娠するとは限らないし、無事出産の暁には子ども手当は廃止されているかもしれないですよね」　その可能性もなきにしもあらずだ。　子ども手当の使い道について子どものいる主婦に聞くと、将来の教育費のために貯蓄に回すという人が多かった。それについても、　「子どもが欲しくてもできなかった家庭がその費用を負担するのはとてもお気の毒な気がします。それに本当に子どものために使われるのならいいのですが、親がギャンブルに使ったり、親の遊興費に使われるために私たちの税金を使ってほしくないですね」と由梨さん。　バツイチの綾さんは、「子どものいない夫婦も、独身も、働いて税金を納めることで次世代を担う子どもたちを育てることに貢献する。それが子ども手当だと思っていましたが、子どものいる家庭にいくはずのお金がどんどん減らされ、それがどこへ行くのかわからないし、申請書の偽装で、私たちの税金が外国人の子どものところに行くのは納得ができません」と制度の不備に怒っている。　　「所得制限限度額のある児童手当を増額するべきなのに、全世帯平等に子ども手当てをばらまくのは選挙のための人気とりしか思えません。これで政権が変われば子ども手当はどうなるのか？」　もしこのまま子ども手当をばら撒かれれば、将来子ども手当をもらった子どもたちが増税という形でつけを払わされるのではと綾さんは心配もしていたが、財政難を地方に泣きつく地方負担に地方自治体から反発の声が上がっている。　一体どうなってしまうのか？ 今後の子ども手当をしっかり見守りたい。　ところで今回、子どものいない独身の人たちに意見を聞いたのだが、「子ども手当」は自分たちには関係ないのでよく分からないという独女が多かった。　介護保険についても、実際自分が親の介護をする立場になって初めて内容かを知ったという人が多いのだが、どんな制度も国会を通過して施行されれば私たちの納めた税金が使われるのだ。知ることも文句を言うことだって私たちの権利だと思う。無関心でいるよりはよほどいいのではないだろうか。（オフィスエムツー／佐枝せつこ）</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "train_dataset = Dataset.get_by_name(ws, \"livedoor\").keep_columns([\"text\",\"label\"])\n",
    "train_dataset.take(5).to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 自動機械学習 Automated Machine Learning\n",
    "## 2.1 設定と制約条件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自動機械学習 Automated Machine Learning の設定と学習を行っていきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.automl.core.featurization import FeaturizationConfig\n",
    "featurization_config = FeaturizationConfig()\n",
    "# テキストデータの言語を指定します。日本語の場合は \"jpn\" と指定します。\n",
    "featurization_config = FeaturizationConfig(dataset_language=\"jpn\") # 英語の場合は下記をコメントアウトしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 明示的に `text` の列がテキストデータであると指定します。\n",
    "featurization_config.add_column_purpose('text', 'Text')\n",
    "#featurization_config.blocked_transformers = ['TfIdf','CountVectorizer']  # BERT のみを利用したい場合はコメントアウトを外します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自動機械学習の設定\n",
    "automl_settings = {\n",
    "    \"experiment_timeout_hours\" : 2,  # 学習時間 (hour)\n",
    "    \"primary_metric\": 'accuracy',  # 評価指標\n",
    "    \"max_concurrent_iterations\": 4,  # 計算環境の最大並列数 \n",
    "    \"max_cores_per_iteration\": -1,\n",
    "    \"enable_dnn\": True, # 深層学習を有効\n",
    "    \"enable_early_stopping\": False,\n",
    "    \"validation_size\": 0.2,\n",
    "    \"verbosity\": logging.INFO,\n",
    "    \"force_text_dnn\": True,\n",
    "    #\"n_cross_validations\": 5,\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(task = 'classification', \n",
    "                             debug_log = 'automl_errors.log',\n",
    "                             compute_target=compute_target,\n",
    "                             training_data=train_dataset,\n",
    "                             label_column_name=target_column_name,\n",
    "                             featurization=featurization_config,\n",
    "                             **automl_settings\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 モデル学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自動機械学習 Automated Machine Learning によるモデル学習を開始します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Running on remote or ADB.\n"
    }
   ],
   "source": [
    "automl_run = experiment.submit(automl_config, show_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_id を出力\n",
    "automl_run.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Run(Experiment: livedoor-news-classification-BERT,\nId: AutoML_e69a63ae-ef52-4783-9a9f-527d69d7cc9d,\nType: automl,\nStatus: Preparing)",
      "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>livedoor-news-classification-BERT</td><td>AutoML_e69a63ae-ef52-4783-9a9f-527d69d7cc9d</td><td>automl</td><td>Preparing</td><td><a href=\"https://ml.azure.com/experiments/livedoor-news-classification-BERT/runs/AutoML_e69a63ae-ef52-4783-9a9f-527d69d7cc9d?wsid=/subscriptions/9c0f91b8-eb2f-484c-979c-15848c098a6b/resourcegroups/azureml_text/workspaces/azureml_text\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# Azure Machine Learning studio の URL を出力\n",
    "automl_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 途中でセッションが切れた場合の対処\n",
    "# from azureml.train.automl.run import AutoMLRun\n",
    "# ws = Workspace.from_config()\n",
    "# experiment = ws.experiments['livedoor-news-classification-BERT'] \n",
    "# run_id = \"AutoML_e69a63ae-ef52-4783-9a9f-527d69d7cc9d\"\n",
    "# automl_run = AutoMLRun(experiment, run_id = run_id)\n",
    "# automl_run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 モデルの登録"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一番精度が高いモデルを抽出\n",
    "best_run, fitted_model = automl_run.get_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルファイル(.pkl) のダウンロード\n",
    "model_dir = '../model'\n",
    "best_run.download_file('outputs/model.pkl', model_dir + '/model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Registering model livedoor-model\n"
    }
   ],
   "source": [
    "# Azure ML へモデル登録\n",
    "model_name = 'livedoor-model'\n",
    "model = Model.register(model_path = model_dir + '/model.pkl',\n",
    "                       model_name = model_name,\n",
    "                       tags=None,\n",
    "                       workspace=ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. テストデータに対する予測値の出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "trained_model = joblib.load(model_dir + '/model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "PipelineWithYTransformations(Pipeline={'memory': None, 'steps': [('datatransformer', DataTransformer(enable_dnn=None, enable_feature_sweeping=None,\n        feature_sweeping_config=None, feature_sweeping_timeout=None,\n        featurization_config=None, force_text_dnn=None,\n        is_cross_validation=None, is_onnx_compatible=Non..., n_jobs=-1, penalty='none',\n           power_t=0.1111111111111111, random_state=None, tol=0.001))]},\n               y_transformer={}, y_transformer_name='LabelEncoder')"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = Dataset.get_by_name(ws, \"livedoor\").keep_columns([\"text\"])\n",
    "predicted = trained_model.predict_proba(test_dataset.to_pandas_dataframe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. モデルの解釈\n",
    "一番精度が良かったチャンピョンモデルを選択し、モデルの解釈をしていきます。  \n",
    "モデルに含まれるライブラリを予め Python 環境にインストールする必要があります。[automl_env.yml](https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/automated-machine-learning/automl_env.yml)を用いて、conda の仮想環境に必要なパッケージをインストールしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "t\": false, \"TransformationParams\": null}, \"Transformer2\": {\"Input\": [\"Transformer1\"], \"TransformationFunction\": \"TfIdf\", \"Operator\": \"CharGram\", \"FeatureType\": null, \"ShouldOutput\": true, \"TransformationParams\": {\"analyzer\": \"char\", \"binary\": false, \"decode_error\": \"strict\", \"encoding\": \"utf-8\", \"input\": \"content\", \"lowercase\": true, \"max_df\": 0.95, \"max_features\": null, \"min_df\": 1, \"ngram_range\": [3, 3], \"norm\": \"l2\", \"smooth_idf\": true, \"stop_words\": null, \"strip_accents\": null, \"sublinear_tf\": false, \"token_pattern\": \"(?u)\\\\\\\\b\\\\\\\\w\\\\\\\\w+\\\\\\\\b\", \"use_idf\": false, \"vocabulary\": null}}}, \"Value\": \" ei\"}',\n '{\"FinalTransformerName\": \"Transformer2\", \"Transformations\": {\"Transformer1\": {\"Input\": [\"text\"], \"TransformationFunction\": \"StringCast\", \"Operator\": null, \"FeatureType\": \"Text\", \"ShouldOutput\": false, \"TransformationParams\": null}, \"Transformer2\": {\"Input\": [\"Transformer1\"], \"TransformationFunction\": \"TfIdf\", \"Operator\": \"CharGram\", \"FeatureType\": null, \"ShouldOutput\": true, \"TransformationParams\": {\"analyzer\": \"char\", \"binary\": false, \"decode_error\": \"strict\", \"encoding\": \"utf-8\", \"input\": \"content\", \"lowercase\": true, \"max_df\": 0.95, \"max_features\": null, \"min_df\": 1, \"ngram_range\": [3, 3], \"norm\": \"l2\", \"smooth_idf\": true, \"stop_words\": null, \"strip_accents\": null, \"sublinear_tf\": false, \"token_pattern\": \"(?u)\\\\\\\\b\\\\\\\\w\\\\\\\\w+\\\\\\\\b\", \"use_idf\": false, \"vocabulary\": null}}}, \"Value\": \" el\"}',\n '{\"FinalTransformerName\": \"Transformer2\", \"Transformations\": {\"Transformer1\": {\"Input\": [\"text\"], \"TransformationFunction\": \"StringCast\", \"Operator\": null, \"FeatureType\": \"Text\", \"ShouldOutput\": false, \"TransformationParams\": null}, \"Transformer2\": {\"Input\": [\"Transformer1\"], \"TransformationFunction\": \"TfIdf\", \"Operator\": \"CharGram\", \"FeatureType\": null, \"ShouldOutput\": true, \"TransformationParams\": {\"analyzer\": \"char\", \"binary\": false, \"decode_error\": \"strict\", \"encoding\": \"utf-8\", \"input\": \"content\", \"lowercase\": true, \"max_df\": 0.95, \"max_features\": null, \"min_df\": 1, \"ngram_range\": [3, 3], \"norm\": \"l2\", \"smooth_idf\": true, \"stop_words\": null, \"strip_accents\": null, \"sublinear_tf\": false, \"token_pattern\": \"(?u)\\\\\\\\b\\\\\\\\w\\\\\\\\w+\\\\\\\\b\", \"use_idf\": false, \"vocabulary\": null}}}, \"Value\": \" em\"}',\n '{\"FinalTransformerName\": \"Transformer2\", \"Transformations\": {\"Transformer1\": {\"Input\": [\"text\"], \"TransformationFunction\": \"StringCast\", \"Operator\": null, \"FeatureType\": \"Text\", \"ShouldOutput\": false, \"TransformationParams\": null}, \"Transformer2\": {\"Input\": [\"Transformer1\"], \"TransformationFunction\": \"TfIdf\", \"Operator\": \"CharGram\", \"FeatureType\": null, \"ShouldOutput\": true, \"TransformationParams\": {\"analyzer\": \"char\", \"binary\": false, \"decode_error\": \"strict\", \"encoding\": \"utf-8\", \"input\": \"content\", \"lowercase\": true, \"max_df\": 0.95, \"max_features\": null, \"min_df\": 1, \"ngram_range\": [3, 3], \"norm\": \"l2\", \"smooth_idf\": true, \"stop_words\": null, \"strip_accents\": null, \"sublinear_tf\": false, \"token_pattern\": \"(?u)\\\\\\\\b\\\\\\\\w\\\\\\\\w+\\\\\\\\b\", \"use_idf\": false, \"vocabulary\": null}}}, \"Value\": \" en\"}',\n '{\"FinalTransformerName\": \"Transformer2\", \"Transformations\": {\"Transformer1\": {\"Input\": [\"text\"], \"TransformationFunction\": \"StringCast\", \"Operator\": null, \"FeatureType\": \"Text\", \"ShouldOutput\": false, \"TransformationParams\": null}, \"Transformer2\": {\"Input\": [\"Transformer1\"], \"TransformationFunction\": \"TfIdf\", \"Operator\": \"CharGram\", \"FeatureType\": null, \"ShouldOutput\": true, \"TransformationParams\": {\"analyzer\": \"char\", \"binary\": false, \"decode_error\": \"strict\", \"encoding\": \"utf-8\", \"input\": \"content\", \"lowercase\": true, \"max_df\": 0.95, \"max_features\": null, \"min_df\": 1, \"ngram_range\": [3, 3], \"norm\": \"l2\", \"smooth_idf\": true, \"stop_words\": null, \"strip_accents\": null, \"sublinear_tf\": false, \"token_pattern\": \"(?u)\\\\\\\\b\\\\\\\\w\\\\\\\\w+\\\\\\\\b\", \"use_idf\": false, \"vocabulary\": null}}}, \"Value\": \" eo\"}',\n '{\"FinalTransformerName\": \"Transformer2\", \"Transformations\": {\"Transformer1\": {\"Input\": [\"text\"], \"TransformationFunction\": \"StringCast\", \"Operator\": null, \"FeatureType\": \"Text\", \"ShouldOutput\": false, \"TransformationParams\": null}, \"Transformer2\": {\"Input\": [\"Transformer1\"], \"TransformationFunction\": \"TfIdf\", \"Operator\": \"CharGram\", \"FeatureType\": null, \"ShouldOutput\": true, \"TransformationParams\": {\"analyzer\": \"char\", \"binary\": false, \"decode_error\": \"strict\", \"encoding\": \"utf-8\", \"input\": \"content\", \"lowercase\": true, \"max_df\": 0.95, \"max_features\": null, \"min_df\": 1, \"ngram_range\": [3, 3], \"norm\": \"l2\", \"smooth_idf\": true, \"stop_words\": null, \"strip_accents\": null, \"sublinear_tf\": false, \"token_pattern\": \"(?u)\\\\\\\\b\\\\\\\\w\\\\\\\\w+\\\\\\\\b\", \"use_idf\": false, \"vocabulary\": null}}}, \"Value\": \" ep\"}',\n '{\"FinalTransformerName\": \"Transformer2\", \"Transformations\": {\"Transformer1\": {\"Input\": [\"text\"], \"TransformationFunction\": \"StringCast\", \"Operator\": null, \"FeatureType\": \"Text\", \"ShouldOutput\": false, \"TransformationParams\": null}, \"Transformer2\": {\"Input\": [\"Transformer1\"], \"TransformationFunction\": \"TfIdf\", \"Operator\": \"CharGram\", \"FeatureType\": null, \"ShouldOutput\": true, \"TransformationParams\": {\"analyzer\": \"char\", \"binary\": false, \"decode_error\": \"strict\", \"encoding\": \"utf-8\", \"input\": \"content\", \"lowercase\": true, \"max_df\": 0.95, \"max_features\": null, \"min_df\": 1, \"ngram_range\": [3, 3], \"norm\": \"l2\", \"smooth_idf\": true, \"stop_words\": null, \"strip_accents\": null, \"sublinear_tf\": false, \"token_pattern\": \"(?u)\\\\\\\\b\\\\\\\\w\\\\\\\\w+\\\\\\\\b\", \"use_idf\": false, \"vocabulary\": null}}}, \"Value\": \" eq\"}',\n '{\"FinalTransformerName\": \"Transformer2\", \"Transformations\": {\"Transformer1\": {\"Input\": [\"text\"], \"TransformationFunction\": \"StringCast\", \"Operator\": null, \"FeatureType\": \"Text\", \"ShouldOutput\": false, \"TransformationParams\": null}, \"Transformer2\": {\"Input\": [\"Transformer1\"], \"TransformationFunction\": \"TfIdf\", \"Operator\": \"CharGram\", \"FeatureType\": null, \"ShouldOutput\": true, \"TransformationParams\": {\"analyzer\": \"char\", \"binary\": false, \"decode_error\": \"strict\", \"encoding\": \"utf-8\", \"input\": \"content\", \"lowercase\": true, \"max_df\": 0.95, \"max_features\": null, \"min_df\": 1, \"ngram_range\": [3, 3], \"norm\": \"l2\", \"smooth_idf\": true, \"stop_words\": null, \"strip_accents\": null, \"sublinear_tf\": false, \"token_pattern\": \"(?u)\\\\\\\\b\\\\\\\\w\\\\\\\\w+\\\\\\\\b\", \"use_idf\": false, \"vocabulary\": null}}}, \"Value\": \" er\"}',\n '{\"FinalTransformerName\": \"Transformer2\", \"Transformations\": {\"Transformer1\": {\"Input\": [\"text\"], \"TransformationFunction\": \"StringCast\", \"Operator\": null, \"FeatureType\": \"Text\", \"ShouldOutput\": false, \"TransformationParams\": null}, \"Transformer2\": {\"Input\": [\"Transformer1\"], \"TransformationFunction\": \"TfIdf\", \"Operator\": \"CharGram\", \"FeatureType\": null, \"ShouldOutput\": true, \"TransformationParams\": {\"analyzer\": \"char\", \"binary\": false, \"decode_error\": \"strict\", \"encoding\": \"utf-8\", \"input\": \"content\", \"lowercase\": true, \"max_df\": 0.95, \"max_features\": null, \"min_df\": 1, \"ngram_range\": [3, 3], \"norm\": \"l2\", \"smooth_idf\": true, \"stop_words\": null, \"strip_accents\": null, \"sublinear_tf\": false, \"token_pattern\": \"(?u)\\\\\\\\b\\\\\\\\w\\\\\\\\w+\\\\\\\\b\", \"use_idf\": false, \"vocabulary\": null}}}, \"Value\": \" es\"}',\n '{\"FinalTransformerName\": \"Transformer2\", \"Transformations\": {\"Transformer1\": {\"Input\": [\"text\"], \"TransformationFunction\": \"StringCast\", \"Operator\": null, \"FeatureType\": \"Text\", \"ShouldOutput\": false, \"TransformationParams\": null}, \"Transformer2\": {\"Input\": [\"Transformer1\"], \"TransformationFunction\": \"TfIdf\", \"Operator\": \"CharGram\", \"FeatureType\": null, \"ShouldOutput\": true, \"TransformationParams\": {\"analyzer\": \"char\", \"binary\": false, \"decode_error\": \"strict\", \"encoding\": \"utf-8\", \"input\": \"content\", \"lowercase\": true, \"max_df\": 0.95, \"max_features\": null, \"min_df\": 1, \"ngram_range\": [3, 3], \"norm\": \"l2\", \"smooth_idf\": true, \"stop_words\": null, \"strip_accents\": null, \"sublinear_tf\": false, \"token_pattern\": \"(?u)\\\\\\\\b\\\\\\\\w\\\\\\\\w+\\\\\\\\b\", \"use_idf\": false, \"vocabulary\": null}}}, \"Value\": \" et\"}',\n '{\"FinalTransformerName\": \"Transformer2\", \"Transformations\": {\"Transformer1\": {\"Input\": [\"text\"], \"TransformationFunction\": \"StringCast\", \"Operator\": null, \"FeatureType\": \"Text\", \"ShouldOutput\": false, \"TransformationParams\": null}, \"Transformer2\": {\"Input\": [\"Transformer1\"], \"TransformationFunction\": \"TfIdf\", \"Operator\": \"CharGram\", \"FeatureType\": null, \"ShouldOutput\": true, \"TransformationParams\": {\"analyzer\": \"char\", \"binary\": false, \"decode_error\": \"strict\", \"encoding\": \"utf-8\", \"input\": \"content\", \"lowercase\": true, \"max_df\": 0.95, \"max_features\": null, \"min_df\": 1, \"ngram_range\": [3, 3], \"norm\": \"l2\", \"smooth_idf\": true, \"stop_words\": null, \"strip_accents\": null, \"sublinear_tf\": false, \"token_pattern\": \"(?u)\\\\\\\\b\\\\\\\\w\\\\\\\\w+\\\\\\\\b\", \"use_idf\": false, \"vocabulary\": null}}}, \"Value\": \" eu\"}',\n '{\"FinalTransformerName\": \"Transformer2\", \"Transformations\": {\"Transformer1\": {\"Input\": [\"text\"], \"TransformationFunction\": \"StringCast\", \"Operator\": null, \"FeatureType\": \"Text\", \"ShouldOutput\": false, \"TransformationParams\": null}, \"Transformer2\": {\"Input\": [\"Transformer1\"], \"TransformationFunction\": \"TfIdf\", \"Operator\": \"CharGram\", \"FeatureType\": null, \"ShouldOutput\": true, \"TransformationParams\": {\"analyzer\": \"char\", \"binary\": false, \"decode_error\": \"strict\", \"encoding\": \"utf-8\", \"input\": \"content\", \"lowercase\": true, \"max_df\": 0.95, \"max_features\": null, \"min_df\": 1, \"ngram_range\": [3, 3], \"norm\": \"l2\", \"smooth_idf\": true, \"stop_words\": null, \"strip_accents\": null, \"sublinear_tf\": false, \"token_pattern\": \"(?u)\\\\\\\\b\\\\\\\\w\\\\\\\\w+\\\\\\\\b\", \"use_idf\": false, \"vocabulary\": null}}}, \"Value\": \" ev\"}',\n '{\"FinalTransformerName\": \"Transformer2\", \"Transformations\": {\"Transformer1\": {\"Input\": [\"text\"], \"TransformationFunction\": \"StringCast\", \"Operator\": null, \"FeatureType\": \"Text\", \"ShouldOutput\": false, \"TransformationParams\": null}, \"Transformer2\": {\"Input\": [\"Transformer1\"], \"TransformationFunction\": \"TfIdf\", \"Operator\": \"CharGram\", \"FeatureType\": null, \"ShouldOutput\": true, \"TransformationParams\": {\"analyzer\": \"char\", \"binary\": false, \"decode_error\": \"strict\", \"encoding\": \"utf-8\", \"input\": \"content\", \"lowercase\": true, \"max_df\": 0.95, \"max_features\": null, \"min_df\": 1, \"ngram_range\": [3, 3], \"norm\": \"l2\", \"smooth_idf\": true, \"stop_words\": null, \"strip_accents\": null, \"sublinear_tf\": false, \"token_pattern\": \"(?u)\\\\\\\\b\\\\\\\\w\\\\\\\\w+\\\\\\\\b\", \"use_idf\": false, \"vocabulary\": null}}}, \"Value\": \" ew\"}',\n '{\"FinalTransformerName\": \"Transformer2\", \"Transformations\": {\"Transformer1\": {\"Input\": [\"text\"], \"TransformationFunction\": \"StringCast\", \"Operator\": null, \"FeatureType\": \"Text\", \"ShouldOutput\": false, \"TransformationParams\": null}, \"Transformer2\": {\"Input\": [\"Transformer1\"], \"TransformationFunction\": \"TfIdf\", \"Operator\": \"CharGram\", \"FeatureType\": null, \"ShouldOutput\": true, \"TransformationParams\": {\"analyzer\": \"char\", \"binary\": false, \"decode_error\": \"strict\", \"encoding\": \"utf-8\", \"input\": \"content\", \"lowercase\": true, \"max_df\": 0.95, \"max_features\": null, \"min_df\": 1, \"ngram_range\": [3, 3], \"norm\": \"l2\", \"smooth_idf\": true, \"stop_words\": null, \"strip_accents\": null, \"sublinear_tf\": false, \"token_pattern\": \"(?u)\\\\\\\\b\\\\\\\\w\\\\\\\\w+\\\\\\\\b\", \"use_idf\": false, \"vocabulary\": null}}}, \"Value\": \" ex\"}',\n '{\"FinalTransformerName\": \"Transformer2\", \"Transformations\": {\"Transformer1\": {\"Input\": [\"text\"], \"TransformationFunction\": \"StringCast\", \"Operator\": null, \"FeatureType\": \"Text\", \"ShouldOutput\": false, \"TransformationParams\": null}, \"Transformer2\": {\"Input\": [\"Transformer1\"], \"TransformationFunction\": \"TfIdf\", \"Operator\": \"CharGram\", \"FeatureType\": null, \"ShouldOutput\": true, \"TransformationParams\": {\"analyzer\": \"char\", \"binary\": false, \"decode_error\": \"strict\", \"encoding\": \"utf-8\", \"input\": \"content\", \"lowercase\": true, \"max_df\": 0.95, \"max_features\": null, \"min_df\": 1, \"ngram_range\": [3, 3], \"norm\": \"l2\", \"smooth_idf\": true, \"stop_words\": null, \"strip_accents\": null, \"sublinear_tf\": false, \"token_pattern\": \"(?u)\\\\\\\\b\\\\\\\\w\\\\\\\\w+\\\\\\\\b\", \"use_idf\": false, \"vocabulary\": null}}}, \"Value\": \" ey\"}',\n '{\"FinalTransformerName\": \"Transformer2\", \"Transformations\": {\"Transformer1\": {\"Input\": [\"text\"], \"TransformationFunction\": \"StringCast\", \"Operator\": null, \"FeatureType\": \"Text\", \"ShouldOutput\": false, \"TransformationParams\": null}, \"Transformer2\": {\"Input\": [\"Transformer1\"], \"TransformationFunction\": \"TfIdf\", \"Operator\": \"CharGram\", \"FeatureType\": null, \"ShouldOutput\": true, \"TransformationParams\": {\"analyzer\": \"char\", \"binary\": false, \"decode_error\": \"strict\", \"encoding\": \"utf-8\", \"input\": \"content\", \"lowercase\": true, \"max_df\": 0.95, \"max_features\": null, \"min_df\": 1, \"ngram_range\": [3, 3], \"norm\": \"l2\", \"smooth_idf\": true, \"stop_words\": null, \"strip_accents\": null, \"sublinear_tf\": false, \"token_pattern\": \"(?u)\\\\\\\\b\\\\\\\\w\\\\\\\\w+\\\\\\\\b\", \"use_idf\": false, \"vocabulary\": null}}}, \"Value\": \" e\\\\u30af\"}',\n '{\"FinalTransformerName\": \"Transformer2\", \"Transformations\": {\"Transformer1\": {\"Input\": [\"text\"], \"TransformationFunction\": \"StringCast\", \"Operator\": null, \"FeatureType\": \"Text\", \"ShouldOutput\": false, \"TransformationParams\": null}, \"Transformer2\": {\"Input\": [\"Transformer1\"], \"TransformationFunction\": \"TfIdf\", \"Operator\": \"CharGram\", \"FeatureType\": null, \"ShouldOutput\": true, \"TransformationParams\": {\"analyzer\": \"char\", \"binary\": false, \"decode_error\": \"strict\", \"encoding\": \"utf-8\", \"input\": \"content\", \"lowercase\": true, \"max_df\": 0.95, \"max_features\": null, \"min_df\": 1, \"ngram_range\": [3, 3], \"norm\": \"l2\", \"smooth_idf\": true, \"stop_words\": null, \"strip_accents\": null, \"sublinear_tf\": false, \"token_pattern\": \"(?u)\\\\\\\\b\\\\\\\\w\\\\\\\\w+\\\\\\\\b\", \"use_idf\": false, \"vocabulary\": null}}}, \"Value\": \" e\\\\u30e1\"}',\n '{\"FinalTransformerName\": \"Transformer2\", \"Transformations\": {\"Transformer1\": {\"Input\": [\"text\"], \"TransformationFunction\": \"StringCast\", \"Operator\": null, \"FeatureType\": \"Text\", \"ShouldOutput\": false, \"TransformationParams\": null}, \"Transformer2\": {\"Input\": [\"Transformer1\"], \"TransformationFunction\": \"TfIdf\", \"Operator\": \"CharGram\", \"FeatureType\": null, \"ShouldOutput\": true, \"TransformationParams\": {\"analyzer\": \"char\", \"binary\": false, \"decode_error\": \"strict\", \"encoding\": \"utf-8\", \"input\": \"content\", \"lowercase\": true, \"max_df\": 0.95, \"max_features\": null, \"min_df\": 1, \"ngram_range\": [3, 3], \"norm\": \"l2\", \"smooth_idf\": true, \"stop_words\": null, \"strip_accents\": null, \"sublinear_tf\": false, \"token_pattern\": \"(?u)\\\\\\\\b\\\\\\\\w\\\\\\\\w+\\\\\\\\b\", \"use_idf\": false, \"vocabulary\": null}}}, \"Value\": \" f \"}',\n '{\"FinalTransformerName\": \"Transformer2\", \"Transformations\": {\"Transformer1\": {\"Input\": [\"text\"], \"TransformationFunction\": \"StringCast\", \"Operator\": null, \"FeatureType\": \"Text\", \"ShouldOutput\": false, \"TransformationParams\": null}, \"Transformer2\": {\"Input\": [\"Transformer1\"], \"TransformationFunction\": \"TfIdf\", \"Operator\": \"CharGram\", \"FeatureType\": null, \"ShouldOutput\": true, \"TransformationParams\": {\"analyzer\": \"char\", \"binary\": false, \"decode_error\": \"strict\", \"encoding\": \"utf-8\", \"input\": \"content\", \"lowercase\": true, \"max_df\": 0.95, \"max_features\": null, \"min_df\": 1, \"ngram_range\": [3, 3], \"norm\": \"l2\", \"smooth_idf\": true, \"stop_words\": null, \"strip_accents\": null, \"sublinear_tf\": false, \"token_pattern\": \"(?u)\\\\\\\\b\\\\\\\\w\\\\\\\\w+\\\\\\\\b\", \"use_idf\": false, \"vocabulary\": null}}}, \"Value\": \" f&\"}',\n '{\"FinalTransformerName\": \"Transformer2\", \"Transformations\": {\"Transformer1\": {\"Input\": [\"text\"], \"TransformationFunction\": \"StringCast\", \"Operator\": null, \"FeatureType\": \"Text\", \"ShouldOutput\": false, \"TransformationParams\": null}, \"Transformer2\": {\"Input\": [\"Transformer1\"], \"TransformationFunction\": \"TfIdf\", \"Operator\": \"CharGram\", \"FeatureType\": null, \"ShouldOutput\": true, \"TransformationParams\": {\"analyzer\": \"char\", \"binary\": false, \"decode_error\": \"strict\", \"encoding\": \"utf-8\", \"input\": \"content\", \"lowercase\": true, \"max_df\": 0.95, \"max_features\": null, \"min_df\": 1, \"ngram_range\": [3, 3], \"norm\": \"l2\", \"smooth_idf\": true, \"stop_words\": null, \"strip_accents\": null, \"sublinear_tf\": false, \"token_pattern\": \"(?u)\\\\\\\\b\\\\\\\\w\\\\\\\\w+\\\\\\\\b\", \"use_idf\": false, \"vocabulary\": null}}}, \"Value\": \" f-\"}',\n '{\"FinalTransformerName\": \"Transformer2\", \"Transformations\": {\"Transformer1\": {\"Input\": [\"text\"], \"TransformationFunction\": \"StringCast\", \"Operator\": null, \"FeatureType\": \"Text\", \"ShouldOutput\": false, \"TransformationParams\": null}, \"Transformer2\": {\"Input\": [\"Transformer1\"], \"TransformationFunction\": \"TfIdf\", \"Operator\": \"CharGram\", \"FeatureType\": null, \"ShouldOutput\": true, \"TransformationParams\": {\"analyzer\": \"char\", \"binary\": false, \"decode_error\": \"strict\", \"encoding\": \"utf-8\", \"input\": \"content\", \"lowercase\": true, \"max_df\": 0.95, \"max_features\": null, \"min_df\": 1, \"ngram_range\": [3, 3], \"norm\": \"l2\", \"smooth_idf\": true, \"stop_words\": null, \"strip_accents\": null, \"sublinear_tf\": false, \"token_pattern\": \"(?u)\\\\\\\\b\\\\\\\\w\\\\\\\\w+\\\\\\\\b\", \"use_idf\": false, \"vocabulary\": null}}}, \"Value\": \" f/\"}',\n '{\"FinalTransformerName\": \"Transformer2\", \"Transformations\": {\"Transformer1\": {\"Input\": [\"text\"], \"TransformationFunction\": \"StringCast\", \"Operator\": null, \"FeatureType\": \"Text\", \"ShouldOutput\": false, \"TransformationParams\": null}, \"Transformer2\": {\"Input\": [\"Transformer1\"], \"TransformationFunction\": \"TfIdf\", \"Operator\": \"CharGram\", \"FeatureType\": null, \"ShouldOutput\": true, \"TransformationParams\": {\"analyzer\": \"char\", \"binary\": false, \"decode_error\": \"strict\", \"encoding\": \"utf-8\", \"input\": \"content\", \"lowercase\": true, \"max_df\": 0.95, \"max_features\": null, \"min_df\": 1, \"ngram_range\": [3, 3], \"norm\": \"l2\", \"smooth_idf\": true, \"stop_words\": null, \"strip_accents\": null, \"sublinear_tf\": false, \"token_pattern\": \"(?u)\\\\\\\\b\\\\\\\\w\\\\\\\\w+\\\\\\\\b\", \"use_idf\": false, \"vocabulary\": null}}}, \"Value\": \" f0\"}',\n '{\"FinalTransformerName\": \"Transformer2\", \"Transformations\": {\"Transformer1\": {\"Input\": [\"text\"], \"TransformationFunction\": \"StringCast\", \"Operator\": null, \"FeatureType\": \"Text\", \"ShouldOutput\": false, \"TransformationParams\": null}, \"Transformer2\": {\"Input\": [\"Transformer1\"], \"TransformationFunction\": \"TfIdf\", \"Operator\": \"CharGram\", \"FeatureType\": null, \"ShouldOutput\": true, \"TransformationParams\": {\"analyzer\": \"char\", \"binary\": false, \"decode_error\": \"strict\", \"encoding\": \"utf-8\", \"input\": \"content\", \"lowercase\": true, \"max_df\": 0.95, \"max_features\": null, \"min_df\": 1, \"ngram_range\": [3, 3], \"norm\": \"l2\", \"smooth_idf\": true, \"stop_words\": null, \"strip_accents\": null, \"sublinear_tf\": false, \"token_pattern\": \"(?u)\\\\\\\\b\\\\\\\\w\\\\\\\\w+\\\\\\\\b\", \"use_idf\": false, \"vocabulary\": null}}}, \"Value\": \" f1\"}',\n '{\"FinalTransformerName\": \"Transformer2\", \"Transformations\": {\"Transformer1\": {\"Input\": [\"text\"], \"TransformationFunction\": \"StringCast\", \"Operator\": null, \"FeatureType\": \"Text\", \"ShouldOutput\": false, \"TransformationParams\": null}, \"Transformer2\": {\"Input\": [\"Transformer1\"], \"TransformationFunction\": \"TfIdf\", \"Operator\": \"CharGram\", \"FeatureType\": null, \"ShouldOutput\": true, \"TransformationParams\": {\"analyzer\": \"char\", \"binary\": false, \"decode_error\": \"strict\", \"encoding\": \"utf-8\", \"input\": \"content\", \"lowercase\": true, \"max_df\": 0.95, \"max_features\": null, \"min_df\": 1, \"ngram_range\": [3, 3], \"norm\": \"l2\", \"smooth_idf\": true, \"stop_words\": null, \"strip_accents\": null, \"sublinear_tf\": false, \"token_pattern\": \"(?u)\\\\\\\\b\\\\\\\\w\\\\\\\\w+\\\\\\\\b\", \"use_idf\": false, \"vocabulary\": null}}}, \"Value\": \" f2\"}',\n '{\"FinalTransformerName\": \"Transformer2\", \"Transformations\": {\"Transformer1\": {\"Input\": [\"text\"], \"TransformationFunction\": \"StringCast\", \"Operator\": null, \"FeatureType\": \"Text\", \"ShouldOutput\": false, \"TransformationParams\": null}, \"Transformer2\": {\"Input\": [\"Transformer1\"], \"TransformationFunction\": \"TfIdf\", \"Operator\": \"CharGram\", \"FeatureType\": null, \"ShouldOutput\": true, \"TransformationParams\": {\"analyzer\": \"char\", \"binary\": false, \"decode_error\": \"strict\", \"encoding\": \"utf-8\", \"input\": \"content\", \"lowercase\": true, \"max_df\": 0.95, \"max_features\": null, \"min_df\": 1, \"ngram_range\": [3, 3], \"norm\": \"l2\", \"smooth_idf\": true, \"stop_words\": null, \"strip_accents\": null, \"sublinear_tf\": false, \"token_pattern\": \"(?u)\\\\\\\\b\\\\\\\\w\\\\\\\\w+\\\\\\\\b\", \"use_idf\": false, \"vocabulary\": null}}}, \"Value\": \" f4\"}',\n ...]"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "# 特徴量エンジニアリング後の変数名の確認\n",
    "fitted_model.named_steps['datatransformer'].get_json_strs_for_engineered_feature_names()\n",
    "#fitted_model.named_steps['datatransformer']. get_engineered_feature_names ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['StringCast-CharGramTfIdf',\n 'StringCast-WordGramTfIdf',\n 'StringCast-StringConcatTransformer-PretrainedTextDNNTransformer']"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "# 特徴エンジニアリングのプロセスの可視化\n",
    "text_transformations_used = []\n",
    "for column_group in fitted_model.named_steps['datatransformer'].get_featurization_summary():\n",
    "    text_transformations_used.extend(column_group['Transformations'])\n",
    "text_transformations_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "anshirga"
   }
  ],
  "compute": [
   "AML Compute"
  ],
  "datasets": [
   "None"
  ],
  "deployment": [
   "None"
  ],
  "exclude_from_index": false,
  "framework": [
   "None"
  ],
  "friendly_name": "DNN Text Featurization",
  "index_order": 2,
  "kernel_info": {
   "name": "azureml180"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "tags": [
   "None"
  ],
  "task": "Text featurization using DNNs for classification"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}